{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "# import re\n",
    "import regex as re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import PyPDF2\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "pd.set_option('display.max_columns', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD = os.getcwd()\n",
    "DATA_PATH = PWD + \"/data/\"\n",
    "\n",
    "FY_DATA_PATH = DATA_PATH + \"financial-statements/\"\n",
    "FY_BASE_NAME = \"UBC-FY\"\n",
    "\n",
    "GENDER_DATA = DATA_PATH + \"name-gender/data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually Set page ranges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_limits = {\n",
    "    '2020':{'min':46, 'max':148},\n",
    "    '2021':{'min':42, 'max':141},\n",
    "    '2022':{'min':45, 'max':165},\n",
    "    '2023':{'min':44, 'max':172},\n",
    "    '2024':{'min':43, 'max':188},}\n",
    "\n",
    "# page_limits = {\n",
    "#     '2024':{'min':43, 'max':188}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def null_str_to_nan(test_number):\n",
    "\n",
    "    if test_number.isnumeric():\n",
    "        return test_number\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def is_numeric(test_string):\n",
    "\n",
    "    return test_string.lstrip('-').replace(',','').replace(\"(\", \"\").replace(\")\", \"\").isnumeric()\n",
    "\n",
    "\n",
    "def standardise_name(text):\n",
    "    # \"john heh h heh h,  h  doe her y\" -> \"JOHN-HEH-HEH,DOE-HER\"\n",
    "    # Remove single letters, but exclude cases where a single letter is followed by a comma or apostrophe\n",
    "    text = re.sub(r'\\b([a-zA-Z])(?![,\\'])\\b', '', text)\n",
    "\n",
    "    # Replace all whitespace (and compress spaces) with a single '-'\n",
    "    text = re.sub(r'\\s+', '-', text.strip())\n",
    "    # Ensure no hyphen comes immediately before or after a comma\n",
    "    text = re.sub(r'-,', ',', text)  # Remove hyphen before a comma\n",
    "    text = re.sub(r',-', ',', text)  # Remove hyphen after a comma\n",
    "\n",
    "    text = re.sub(r'-+', '-', text)\n",
    "\n",
    "    return text.upper()\n",
    "\n",
    "\n",
    "def parse_one_line_information(one_line):\n",
    "    # Regex pattern to match name, salary, and expense\n",
    "    pattern = r'([A-Za-z\\p{L}.]+[\\-,.A-Za-z\\p{L},\\s]*)\\s*([\\d,()-]+)\\s*([\\d,()-]+)'\n",
    "\n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, one_line)\n",
    "\n",
    "    # Process matches to clean up data\n",
    "    parsed_data = {\n",
    "        \"name\": [],\n",
    "        \"salary\": [],\n",
    "        \"expense\": []\n",
    "    }\n",
    "\n",
    "    for match in matches:\n",
    "        name, salary, expense = match\n",
    "        \n",
    "        # Clean salary and expense\n",
    "        salary = salary.replace(',', '').replace('(', '-').replace(')', '').strip()\n",
    "        salary = float(salary) if salary.lstrip('-').isdigit() else np.nan\n",
    "        \n",
    "        expense = expense.replace(',', '').replace('(', '-').replace(')', '').strip()\n",
    "        expense = float(expense) if expense.lstrip('-').isdigit() else np.nan\n",
    "        \n",
    "        # Append to parsed_data\n",
    "        name = standardise_name(name)\n",
    "        parsed_data[\"name\"].append(name.strip().upper())\n",
    "        parsed_data[\"salary\"].append(salary)\n",
    "        parsed_data[\"expense\"].append(expense)\n",
    "\n",
    "    parse_df = pd.DataFrame(parsed_data)\n",
    "\n",
    "    return parse_df\n",
    "\n",
    "\n",
    "def pdf_to_df(pdf_file, year, page_start, page_end):\n",
    "\n",
    "    pdfFileObj = open(pdf_file, 'rb')\n",
    "    \n",
    "    # creating a pdf reader object\n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "    \n",
    "    column_header_pattern = r\"Name\\s*Remuneration\\s*Expenses\"\n",
    "    column_header_pattern2 = r\"\\s*Remuneration\\s*Expenses\"\n",
    "\n",
    "    data = pd.DataFrame({'name':[], 'year':[], 'salary':[], 'expense':[]})\n",
    "\n",
    "    for page in np.arange(page_start, page_end, 1):\n",
    "\n",
    "        page = int(page)\n",
    "        pageObj = pdfReader.getPage(page)\n",
    "        pagetxt = pageObj.extractText()\n",
    "\n",
    "\n",
    "        begin = 0\n",
    "        finished_prof = 0\n",
    "        prof = []\n",
    "        old_line = ''\n",
    "        use_old_line = False\n",
    "\n",
    "        for index, line in enumerate(pagetxt.split('\\n')):\n",
    "\n",
    "            if begin == 1:\n",
    "\n",
    "                if use_old_line:\n",
    "                    line = old_line + line\n",
    "                    use_old_line = False\n",
    "                    # print(line)\n",
    "\n",
    "\n",
    "                contains_number = bool(re.search(r'\\d', line))\n",
    "                if not contains_number and 'Remuneration' not in line and line.strip():\n",
    "                    old_line = line\n",
    "                    use_old_line = True\n",
    "                    continue\n",
    "\n",
    "\n",
    "\n",
    "                if year in [2021, 2022, 2023]:\n",
    "                    if finished_prof == 1:\n",
    "                        name = ''\n",
    "                        pay = null_str_to_nan(prof[-2].replace(',','').replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "                        exp = null_str_to_nan(prof[-1].replace(',','').replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "                        for n in prof[0:-2]:\n",
    "                            name = name + n.upper() + ' '\n",
    "                            \n",
    "                        name = standardise_name(name)\n",
    "                        new_row = pd.DataFrame({'name':[name], 'year':[int(year)], 'salary':[pay], 'expense':[exp]})\n",
    "                        data = pd.concat([data, new_row], ignore_index=True)\n",
    "                        \n",
    "                        prof = []\n",
    "                        finished_prof = 0\n",
    "                        \n",
    "                    if len(line.split()) != 0:                       \n",
    "\n",
    "                        cleaned_line = re.sub(column_header_pattern, \"\", line).replace(\"*\", \"\").strip()\n",
    "\n",
    "                        if finished_prof == 0 and (cleaned_line.split()[-1] == '-' or is_numeric(cleaned_line.split()[-1])) and \"$\" not in cleaned_line: \n",
    "                            for k in cleaned_line.split():\n",
    "                                prof.append(k)\n",
    "                            finished_prof = 1\n",
    "                            \n",
    "            \n",
    "                        else:\n",
    "                            for k in line.split():\n",
    "                                prof.append(k)               \n",
    "                            finished_prof = 0\n",
    "                \n",
    "                elif year in [2020, 2024]:\n",
    "                    \n",
    "                    if year == 2024:\n",
    "                        cleaned_line = re.sub(column_header_pattern, \"\", line).replace(\"*\", \"\").replace(\"(\", \"\").replace(\")\", \"\").strip()\n",
    "                    elif year == 2020:\n",
    "                        cleaned_line = re.sub(column_header_pattern2, \"\", line).replace(\"*\", \"\").replace(\"(\", \"\").replace(\")\", \"\").strip()\n",
    "\n",
    "                    new_row = parse_one_line_information(cleaned_line)\n",
    "                    new_row['year'] = int(year)\n",
    "\n",
    "                    data = pd.concat([data, new_row], ignore_index=True)\n",
    "\n",
    "                old_line = line\n",
    "\n",
    "            \n",
    "            if re.search(column_header_pattern, line, re.DOTALL) or re.search(column_header_pattern2, line, re.DOTALL):\n",
    "\n",
    "                begin = 1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # closing the pdf file object\n",
    "    pdfFileObj.close()\n",
    "\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Year 2021\n",
      "Parsing Year 2022\n",
      "Parsing Year 2023\n",
      "Parsing Year 2024\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'name':[], 'year':[], 'salary':[], 'expense':[]})\n",
    "\n",
    "for i, (year, value) in enumerate(page_limits.items()):\n",
    "\n",
    "    if year  != '2020':\n",
    "        print(f'Parsing Year {year}')\n",
    "\n",
    "        pdf_file = FY_DATA_PATH + FY_BASE_NAME + year + '.pdf'\n",
    "        page_start = value['min']\n",
    "        page_end = value['max']\n",
    "\n",
    "        new_df = pdf_to_df(pdf_file, int(year), page_start, page_end)\n",
    "\n",
    "        df['year'] = df['year'].astype(int)\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "\n",
    "df['year'] = df['year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting by length of name\n",
    "An interesting way to look at longest and shortest names.\n",
    "But also a check to make sure paarsing is not cutting off names or adding different names together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>salary</th>\n",
       "      <th>expense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17940</th>\n",
       "      <td>LI,RI</td>\n",
       "      <td>2023</td>\n",
       "      <td>151182</td>\n",
       "      <td>54163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21067</th>\n",
       "      <td>VU,LY</td>\n",
       "      <td>2023</td>\n",
       "      <td>169466</td>\n",
       "      <td>13338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>FU,HU</td>\n",
       "      <td>2021</td>\n",
       "      <td>123374</td>\n",
       "      <td>3846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6806</th>\n",
       "      <td>YUE,.</td>\n",
       "      <td>2021</td>\n",
       "      <td>76515</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26260</th>\n",
       "      <td>LI,YI</td>\n",
       "      <td>2024</td>\n",
       "      <td>106805.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21265</th>\n",
       "      <td>WIJENDRA-ACHARIGE,LASANTHA-PREMARATHNA</td>\n",
       "      <td>2023</td>\n",
       "      <td>114048</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19441</th>\n",
       "      <td>POTYGUARA-COUTINHO-MARQUES,PAULO-EDUARDO</td>\n",
       "      <td>2023</td>\n",
       "      <td>86307</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>POTYGUARA-COUTINHO-MARQUES,PAULO-EDUARDO</td>\n",
       "      <td>2021</td>\n",
       "      <td>95421</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28066</th>\n",
       "      <td>POTYGUARA-COUTINHO-MARQUES,PAULO-EDUARDO</td>\n",
       "      <td>2024</td>\n",
       "      <td>115035.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11966</th>\n",
       "      <td>POTYGUARA-COUTINHO-MARQUES,PAULO-EDUARDO</td>\n",
       "      <td>2022</td>\n",
       "      <td>99167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30692 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           name  year    salary expense\n",
       "17940                                     LI,RI  2023    151182   54163\n",
       "21067                                     VU,LY  2023    169466   13338\n",
       "1904                                      FU,HU  2021    123374    3846\n",
       "6806                                      YUE,.  2021     76515     484\n",
       "26260                                     LI,YI  2024  106805.0     NaN\n",
       "...                                         ...   ...       ...     ...\n",
       "21265    WIJENDRA-ACHARIGE,LASANTHA-PREMARATHNA  2023    114048     NaN\n",
       "19441  POTYGUARA-COUTINHO-MARQUES,PAULO-EDUARDO  2023     86307     NaN\n",
       "4901   POTYGUARA-COUTINHO-MARQUES,PAULO-EDUARDO  2021     95421     NaN\n",
       "28066  POTYGUARA-COUTINHO-MARQUES,PAULO-EDUARDO  2024  115035.0     NaN\n",
       "11966  POTYGUARA-COUTINHO-MARQUES,PAULO-EDUARDO  2022     99167     NaN\n",
       "\n",
       "[30692 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted = df.sort_values(by='name', key=lambda col: col.str.len(), ascending=True)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group people with similar names\n",
    "\n",
    "There is an inconsistency between years in how names are recorded. We can be somewhat confident they are the same person as the salary year after year is the same. \n",
    "Sometimes we find that a person has added their middle name or removed it. \n",
    "\n",
    "The first way to 'fix' this is to look for all names which are only recorded for a single year.\n",
    "Then check that name with all other names to see if there is a match, i.e. does all the names exist in another name or atleast 1 minus the total number of names exists (I assume only 1 single name is added/removed between years)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = df.groupby('name')['year'].nunique()\n",
    "list_of_single_names = unique_names[unique_names == 1].index.tolist()\n",
    "\n",
    "\n",
    "for single_name in list_of_single_names:\n",
    "\n",
    "    single_components = set(single_name.replace('-', ',').replace(\"'\", ',').split(','))\n",
    "    single_components1 = set(single_name.split(',')[0].replace('-', ',').replace(\"'\", ',').split(','))\n",
    "    single_components2 = set(single_name.split(',')[-1].replace('-', ',').replace(\"'\", ',').split(','))\n",
    "\n",
    "\n",
    "    for unique_name in df['name'].unique().tolist():\n",
    "\n",
    "        if single_name != unique_name:\n",
    "\n",
    "            unique_components = set(unique_name.replace('-', ',').replace(\"'\", ',').split(','))\n",
    "            unique_components1 = set(unique_name.split(',')[0].replace('-', ',').replace(\"'\", ',').split(','))\n",
    "            unique_components2 = set(unique_name.split(',')[-1].replace('-', ',').replace(\"'\", ',').split(','))\n",
    "\n",
    "            # Check for a match (length - 1 components must overlap)\n",
    "            \n",
    "\n",
    "            if (\n",
    "                ((len(single_components1) > 0) and (len(single_components1 & unique_components1) >= len(unique_components) - 1) and (len(single_components1 & unique_components1) > 0)) \n",
    "                and \n",
    "                ((len(single_components2) > 0) and (len(single_components2 & unique_components2) >= len(unique_components) - 2) and (len(single_components2 & unique_components2) > 0)) ):\n",
    "\n",
    "                df.loc[df['name'] == single_name, 'name'] = unique_name\n",
    "                break  # Stop checking once a match is found\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for people with the same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each name within each year\n",
    "name_counts = df.groupby([\"year\", \"name\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "# Merge counts back to the original DataFrame\n",
    "df = df.merge(name_counts, on=[\"year\", \"name\"], how=\"left\")\n",
    "\n",
    "# Assign numbers only to names that appear more than once\n",
    "df[\"name_id\"] = df.groupby([\"year\", \"name\"]).cumcount() + 1  # Start numbering from 1\n",
    "df[\"name_id\"] = df.apply(\n",
    "    lambda x: f\"{x['name']} {x['name_id']}\" if x[\"count\"] > 1 else x[\"name\"],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop the auxiliary count column (optional)\n",
    "df.drop(columns=[\"count\"], inplace=True)\n",
    "\n",
    "rows_with_numbers = df[df[\"name_id\"].str.contains(r\"\\d\", na=False)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work out if male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/p8qnv7p57d73kx2f_7bd35bm0000gn/T/ipykernel_23200/2228208973.py:27: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df = names_data[names_data['Name'].str.contains(name, na=False)]\n",
      "/var/folders/17/p8qnv7p57d73kx2f_7bd35bm0000gn/T/ipykernel_23200/2228208973.py:27: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df = names_data[names_data['Name'].str.contains(name, na=False)]\n"
     ]
    }
   ],
   "source": [
    "unique_names = df[\"name\"].unique()\n",
    "\n",
    "\n",
    "def most_common_gender(gender_list):\n",
    "    # Initialize counts for 'male' and 'female'\n",
    "    male_count = 0\n",
    "    female_count = 0\n",
    "\n",
    "    # Count occurrences of 'male' and 'female', ignoring 'unknown'\n",
    "    for gender in gender_list:\n",
    "        if gender.lower() == 'male':\n",
    "            male_count += 1\n",
    "        elif gender.lower() == 'female':\n",
    "            female_count += 1\n",
    "\n",
    "    # Determine which gender has the most occurrences\n",
    "    if male_count > female_count:\n",
    "        return 'Male'\n",
    "    elif female_count > male_count:\n",
    "        return 'Female'\n",
    "    else:\n",
    "        return 'Unknown'  # Return None if both are equal or the list has no valid entries\n",
    "\n",
    "\n",
    "def guess_gender(name, names_data):\n",
    "    name = name.title()\n",
    "    filtered_df = names_data[names_data['Name'].str.contains(name, na=False)]\n",
    "\n",
    "    if not filtered_df.empty:\n",
    "        gender = filtered_df['Gender'].value_counts().idxmax()\n",
    "        if gender == 'M':\n",
    "            return 'male'\n",
    "        else:\n",
    "            return 'female'\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pass the entire full name to the detector\n",
    "d = gender.Detector()\n",
    "\n",
    "# Load a CSV of names and genders\n",
    "names_data = pd.read_csv(GENDER_DATA)  # Columns: Name, Gender (M/F), Count, Probability\n",
    "\n",
    "# Function to process and estimate gender\n",
    "def estimate_gender(full_name):\n",
    "    # Normalize the name (capitalize each word for consistent processing)\n",
    "    full_name = full_name.title()  # \"CARROLL, MICHAEL\" -> \"Carroll, Michael\"\n",
    "    split_name = full_name.split(',')\n",
    "    first_name = split_name[-1].strip().title()\n",
    "\n",
    "    temp_gender1 = []\n",
    "    temp_gender2 = []\n",
    "\n",
    "    for split_first_name in first_name.split(' '):\n",
    "\n",
    "        split_first_name = split_first_name.strip().title()\n",
    "        temp_gender1.append(d.get_gender(split_first_name))\n",
    "        temp_gender2.append(guess_gender(split_first_name, names_data))\n",
    "\n",
    "\n",
    "    guessed_gender = most_common_gender(temp_gender1 + temp_gender2)\n",
    "\n",
    "    # if guessed_gender == 'unknown':\n",
    "        # print(full_name)\n",
    "        # full_name = full_name.split(',')[-2].strip().title()\n",
    "        # guessed_gender = d.get_gender(full_name)\n",
    "\n",
    "    return guessed_gender\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to the list of names\n",
    "results = [(name, estimate_gender(name)) for name in unique_names]\n",
    "\n",
    "name_gender_dict = dict(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by Gender:\n",
      "Male: 3705\n",
      "Female: 5179\n",
      "Unknown: 1953\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each gender category\n",
    "gender_counts = {\n",
    "    \"Male\": 0,\n",
    "    \"Female\": 0,\n",
    "    \"Unknown\": 0\n",
    "}\n",
    "\n",
    "for _, gender_detect in results:\n",
    "    if gender_detect in gender_counts:\n",
    "        gender_counts[gender_detect] += 1\n",
    "\n",
    "# Print the counts\n",
    "print(\"Counts by Gender:\")\n",
    "for gender_detect, count in gender_counts.items():\n",
    "    print(f\"{gender_detect.capitalize()}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding sex to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['name'].map(name_gender_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensuring salary and expenses are numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['salary'] = pd.to_numeric(df['salary'], errors='coerce')\n",
    "df['expense'] = pd.to_numeric(df['expense'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = DATA_PATH + 'output/salary.csv'\n",
    "\n",
    "df.to_csv(csv_file, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new csv with calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yearly_changes(df, name_id, years):\n",
    "\n",
    "    number_of_years = len(years)\n",
    "\n",
    "    year_range, salary_amount_change, salary_percent_change, yearly_check = [], [], [], []\n",
    "    year_range_str = ''\n",
    "    salary_amount_change_num, salary_percent_change_num = 0, 0\n",
    "\n",
    "    if number_of_years <= 1:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "\n",
    "    for index, year in enumerate(years):\n",
    "\n",
    "        filtered_row = df[(df['year'] == year) & (df['name_id'] == name_id)].iloc[0]\n",
    "\n",
    "        if index + 1 < number_of_years:\n",
    "\n",
    "            if years[index+1] - year == 1:\n",
    "                year_range_str = f\"{year}-{years[index+1]}\"\n",
    "                \n",
    "                filtered_row_new = df[(df['year'] == years[index+1]) & (df['name_id'] == name_id)].iloc[0]\n",
    "                salary_amount_change_num = filtered_row_new['salary'] - filtered_row['salary']\n",
    "                salary_percent_change_num = (filtered_row_new['salary'] - filtered_row['salary'])/filtered_row['salary']\n",
    "\n",
    "                year_range.append(year_range_str)\n",
    "                salary_amount_change.append(salary_amount_change_num)\n",
    "                salary_percent_change.append(salary_percent_change_num)\n",
    "                yearly_check.append(True)\n",
    "\n",
    "                if number_of_years <= 2:\n",
    "                    break\n",
    "        else:\n",
    "            year_range_str = f\"{years[0]}-{year}\"\n",
    "\n",
    "            filtered_row_new = df[(df['year'] == years[0]) & (df['name_id'] == name_id)].iloc[0]\n",
    "            salary_amount_change_num = filtered_row['salary'] - filtered_row_new['salary']\n",
    "            salary_percent_change_num = (filtered_row['salary'] - filtered_row_new['salary'])/filtered_row_new['salary']\n",
    "\n",
    "            year_range.append(year_range_str)\n",
    "            salary_amount_change.append(salary_amount_change_num)\n",
    "            salary_percent_change.append(salary_percent_change_num)\n",
    "            yearly_check.append(False)\n",
    "        \n",
    "\n",
    "    return year_range, salary_amount_change, salary_percent_change, yearly_check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_by_id = df.groupby('name_id')['year'].apply(list).to_dict()\n",
    "\n",
    "calc_df = pd.DataFrame({'name_id':[], 'year_range':[], 'salary_amount_change':[], 'salary_percent_change':[], 'yearly_check':[]})\n",
    "\n",
    "\n",
    "# for unique_name in unique_names:\n",
    "for index, (name_id, years) in enumerate(years_by_id.items()):\n",
    "\n",
    "    if len(years) > 1:\n",
    "        \n",
    "        year_range, salary_amount_change, salary_percent_change, yearly_check = get_yearly_changes(df, name_id, years)\n",
    "\n",
    "        new_row = pd.DataFrame({'name_id':[name_id]*len(year_range), \n",
    "                                'year_range':year_range, \n",
    "                                'salary_amount_change':salary_amount_change, \n",
    "                                'salary_percent_change':salary_percent_change,\n",
    "                                'yearly_check':yearly_check})\n",
    "        \n",
    "        calc_df = pd.concat([calc_df, new_row], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_calcfile = DATA_PATH + 'output/id-calc.csv'\n",
    "\n",
    "\n",
    "calc_df.to_csv(csv_calcfile, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at largest salary increases between years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_df.nlargest(20, 'salary_amount_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berlin_wall_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
